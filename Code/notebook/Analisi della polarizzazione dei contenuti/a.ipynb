{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pasqua\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\pasqua\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "c:\\Users\\pasqua\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(r\"C:\\Users\\pasqu\\Desktop\\progettoasnm\")\n",
    "sys.path.append(r\"C:\\Users\\pasqua\\Desktop\\progettoasnm\")\n",
    "\n",
    "from Code.notebook.graph.GraphConstructor import GraphConstructor\n",
    "from preprocessing.text_preprocessor import TextPreprocessor\n",
    "from models.clustering import Clustering\n",
    "from visualization.cluster_visualizer import ClusterVisualizer\n",
    "from models.sentiment_analysis import SentimentAnalyzer\n",
    "from visualization.sentiment_visualizer import SentimentVisualizer\n",
    "from visualization.wordcloud_visualizer import WordCloudVisualizer\n",
    "from visualization.lda_visualizer import LDAViz\n",
    "from models.topic_modeling import TopicModeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Inizio del processo principale.\")\n",
    "output_dir = r\"../../../notebook//Analisi della polarizzazione dei contenuti//output\"\n",
    "# Costruzione del grafo\n",
    "graph_builder = GraphConstructor(\n",
    "        followers_paths= [\"../../data_extraction/followers.csv\"],\n",
    "        data_paths = [\"../../data_extraction/total_post1.csv\", \"../../data_extraction/total_post2.csv\", \"../../data_extraction/total_post3.csv\"],\n",
    "        info_filepath=\"graph_info.json\",\n",
    "        centralities_filepath=\"centralities_info.json\",\n",
    "    )\n",
    "graph_builder.build_graph()\n",
    "graph = graph_builder.graph\n",
    "\n",
    "# # Estrazione e pre-elaborazione dei testi\n",
    "preprocessor = TextPreprocessor()\n",
    "user_opinions = preprocessor.extract_user_opinions(graph_builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pasqua\\Desktop\\progettoasnm\\Code\\notebook\\Analisi della polarizzazione dei contenuti\\models\\sentiment_analysis.py:41: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sentiment_scores = df_data.groupby(\"thread_user_pk\").apply(\n"
     ]
    }
   ],
   "source": [
    "sentiment_scores = SentimentAnalyzer().extract_sentiments_from_graph(graph_builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering\n",
    "clustering = Clustering(cluster_file=\"output/cluster_labels.pkl\")\n",
    "cluster_labels = clustering.cluster(user_opinions, method=\"dbscan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 5.45 GiB for an array with shape (7915, 92493) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Clustering\u001b[39;00m\n\u001b[0;32m      2\u001b[0m clustering \u001b[38;5;241m=\u001b[39m Clustering()\n\u001b[1;32m----> 3\u001b[0m cluster_labels \u001b[38;5;241m=\u001b[39m \u001b[43mclustering\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcluster\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_opinions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdbscan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Visualizzazione dei cluster\u001b[39;00m\n\u001b[0;32m      6\u001b[0m cluster_visualizer \u001b[38;5;241m=\u001b[39m ClusterVisualizer(output_dir\u001b[38;5;241m=\u001b[39moutput_dir)\n",
      "File \u001b[1;32mc:\\Users\\Utente\\Desktop\\socialNetwork\\progettoasnm\\Code\\notebook\\Analisi della polarizzazione dei contenuti\\models\\clustering.py:23\u001b[0m, in \u001b[0;36mClustering.cluster\u001b[1;34m(self, user_opinions, method, n_clusters)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdbscan\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     22\u001b[0m     model \u001b[38;5;241m=\u001b[39m DBSCAN(metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcosine\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClustering completato.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(user_opinions\u001b[38;5;241m.\u001b[39mkeys(), labels))\n",
      "File \u001b[1;32mc:\\Users\\Utente\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\cluster\\_dbscan.py:446\u001b[0m, in \u001b[0;36mDBSCAN.fit_predict\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    422\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute clusters from a data or distance matrix and predict labels.\u001b[39;00m\n\u001b[0;32m    423\u001b[0m \n\u001b[0;32m    424\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;124;03m        Cluster labels. Noisy samples are given the label -1.\u001b[39;00m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 446\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_\n",
      "File \u001b[1;32mc:\\Users\\Utente\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\cluster\\_dbscan.py:394\u001b[0m, in \u001b[0;36mDBSCAN.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    392\u001b[0m neighbors_model\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[0;32m    393\u001b[0m \u001b[38;5;66;03m# This has worst case O(n^2) memory complexity\u001b[39;00m\n\u001b[1;32m--> 394\u001b[0m neighborhoods \u001b[38;5;241m=\u001b[39m \u001b[43mneighbors_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mradius_neighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    397\u001b[0m     n_neighbors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mlen\u001b[39m(neighbors) \u001b[38;5;28;01mfor\u001b[39;00m neighbors \u001b[38;5;129;01min\u001b[39;00m neighborhoods])\n",
      "File \u001b[1;32mc:\\Users\\Utente\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_base.py:1217\u001b[0m, in \u001b[0;36mRadiusNeighborsMixin.radius_neighbors\u001b[1;34m(self, X, radius, return_distance, sort_results)\u001b[0m\n\u001b[0;32m   1215\u001b[0m     results \u001b[38;5;241m=\u001b[39m neigh_dist, neigh_ind\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1217\u001b[0m     neigh_ind_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunked_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1218\u001b[0m     results \u001b[38;5;241m=\u001b[39m _to_object_array(neigh_ind_list)\n\u001b[0;32m   1220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sort_results:\n",
      "File \u001b[1;32mc:\\Users\\Utente\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1867\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1866\u001b[0m     X_chunk \u001b[38;5;241m=\u001b[39m X[sl]\n\u001b[1;32m-> 1867\u001b[0m D_chunk \u001b[38;5;241m=\u001b[39m pairwise_distances(X_chunk, Y, metric\u001b[38;5;241m=\u001b[39mmetric, n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (X \u001b[38;5;129;01mis\u001b[39;00m Y \u001b[38;5;129;01mor\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m PAIRWISE_DISTANCE_FUNCTIONS\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m   1869\u001b[0m     metric, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m ) \u001b[38;5;129;01mis\u001b[39;00m euclidean_distances:\n\u001b[0;32m   1871\u001b[0m     \u001b[38;5;66;03m# zeroing diagonal, taking care of aliases of \"euclidean\",\u001b[39;00m\n\u001b[0;32m   1872\u001b[0m     \u001b[38;5;66;03m# i.e. \"l2\"\u001b[39;00m\n\u001b[0;32m   1873\u001b[0m     D_chunk\u001b[38;5;241m.\u001b[39mflat[sl\u001b[38;5;241m.\u001b[39mstart :: _num_samples(X) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Utente\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:2039\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   2036\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m distance\u001b[38;5;241m.\u001b[39msquareform(distance\u001b[38;5;241m.\u001b[39mpdist(X, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[0;32m   2037\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(distance\u001b[38;5;241m.\u001b[39mcdist, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m-> 2039\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _parallel_pairwise(X, Y, func, n_jobs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Users\\Utente\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1579\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1576\u001b[0m X, Y, dtype \u001b[38;5;241m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[0;32m   1578\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 1579\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(X, Y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m   1581\u001b[0m \u001b[38;5;66;03m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[0;32m   1582\u001b[0m fd \u001b[38;5;241m=\u001b[39m delayed(_dist_wrapper)\n",
      "File \u001b[1;32mc:\\Users\\Utente\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1000\u001b[0m, in \u001b[0;36mcosine_distances\u001b[1;34m(X, Y)\u001b[0m\n\u001b[0;32m    974\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute cosine distance between samples in X and Y.\u001b[39;00m\n\u001b[0;32m    975\u001b[0m \n\u001b[0;32m    976\u001b[0m \u001b[38;5;124;03mCosine distance is defined as 1.0 minus the cosine similarity.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    997\u001b[0m \u001b[38;5;124;03mscipy.spatial.distance.cosine : Dense matrices only.\u001b[39;00m\n\u001b[0;32m    998\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    999\u001b[0m \u001b[38;5;66;03m# 1.0 - cosine_similarity(X, Y) without copy\u001b[39;00m\n\u001b[1;32m-> 1000\u001b[0m S \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1001\u001b[0m S \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1002\u001b[0m S \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Utente\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1395\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;66;03m# to avoid recursive import\u001b[39;00m\n\u001b[0;32m   1393\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m check_pairwise_arrays(X, Y)\n\u001b[1;32m-> 1395\u001b[0m X_normalized \u001b[38;5;241m=\u001b[39m \u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m Y:\n\u001b[0;32m   1397\u001b[0m     Y_normalized \u001b[38;5;241m=\u001b[39m X_normalized\n",
      "File \u001b[1;32mc:\\Users\\Utente\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:1817\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(X, norm, axis, copy, return_norm)\u001b[0m\n\u001b[0;32m   1814\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1815\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not a supported axis\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m axis)\n\u001b[1;32m-> 1817\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1818\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1819\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1820\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1821\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthe normalize function\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1823\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1824\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1825\u001b[0m     X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[1;32mc:\\Users\\Utente\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:950\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    947\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy.array_api\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m    948\u001b[0m     \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n\u001b[0;32m    949\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmay_share_memory(array, array_orig):\n\u001b[1;32m--> 950\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    951\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\n\u001b[0;32m    952\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    954\u001b[0m     \u001b[38;5;66;03m# always make a copy for non-numpy arrays\u001b[39;00m\n\u001b[0;32m    955\u001b[0m     array \u001b[38;5;241m=\u001b[39m _asarray_with_order(\n\u001b[0;32m    956\u001b[0m         array, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, xp\u001b[38;5;241m=\u001b[39mxp\n\u001b[0;32m    957\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Utente\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_array_api.py:186\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy.array_api\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[0;32m    185\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39masarray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32mc:\\Users\\Utente\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_array_api.py:73\u001b[0m, in \u001b[0;36m_NumPyApiWrapper.asarray\u001b[1;34m(self, x, dtype, device, copy)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21masarray\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# Support copy in NumPy namespace\u001b[39;00m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 73\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m numpy\u001b[38;5;241m.\u001b[39masarray(x, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 5.45 GiB for an array with shape (7915, 92493) and data type float64"
     ]
    }
   ],
   "source": [
    "# Clustering\n",
    "clustering = Clustering(cluster_file=\"output/cluster_labels.pkl\")\n",
    "cluster_labels = clustering.cluster(user_opinions, method=\"dbscan\")\n",
    "\n",
    "# Visualizzazione dei cluster\n",
    "cluster_visualizer = ClusterVisualizer(output_dir=output_dir)\n",
    "cluster_visualizer.visualize(user_opinions, cluster_labels)\n",
    "\n",
    "# Visualizzazione del sentiment\n",
    "sentiment_visualizer = SentimentVisualizer(output_dir=output_dir)\n",
    "\n",
    "# Visualizza la distribuzione del sentiment\n",
    "sentiment_visualizer.visualize_sentiment_distribution(\n",
    "sentiment_scores, cluster_labels\n",
    ")\n",
    "\n",
    "# Visualizza la mappa di calore sentiment vs temi\n",
    "sentiment_visualizer.visualize_sentiment_vs_themes_heatmap(\n",
    "sentiment_scores, user_opinions, cluster_labels\n",
    ")\n",
    "\n",
    "# Identificazione e visualizzazione temi polarizzanti\n",
    "\n",
    "# UnGram\n",
    "polarizing_words = clustering.identify_polarizing_themes(\n",
    "user_opinions, cluster_labels\n",
    ")\n",
    "wordcloud_visualizer = WordCloudVisualizer()\n",
    "wordcloud_visualizer.visualize(polarizing_words, output_dir, \"Un\")\n",
    "\n",
    "# BiGram\n",
    "polarizing_words = clustering.identify_polarizing_themes_bigram(\n",
    "user_opinions, cluster_labels\n",
    ")\n",
    "wordcloud_visualizer.visualize(polarizing_words, output_dir, \"Bi\")\n",
    "\n",
    "# Topic Modeling\n",
    "\n",
    "topic_modeling = TopicModeling()\n",
    "lda_model, dictionary, corpus = topic_modeling.perform_topic_modeling(\n",
    "user_opinions, len(set(cluster_labels.values()))\n",
    ")\n",
    "\n",
    "# Visualizzazione dei temi\n",
    "lda_visualizer = LDAViz()\n",
    "lda_visualizer.visualize(lda_model, corpus, dictionary, output_dir=output_dir)\n",
    "\n",
    "logging.info(\"Processo principale completato.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(cluster_labels.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarizing_words = clustering.identify_polarizing_themes(\n",
    "        user_opinions, cluster_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = clustering.identify_polarizing_themes_bigram(\n",
    "        user_opinions, cluster_labels\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['artificial_intelligence',\n",
       " 'even_artificial',\n",
       " 'manufacture_intelligence',\n",
       " 'intelligence_collected',\n",
       " 'manufactures_artificial',\n",
       " 'humans_manufactures',\n",
       " 'intelligence_humans',\n",
       " 'collected_human',\n",
       " 'cannot_manufacture',\n",
       " 'good_morning',\n",
       " 'art_threads',\n",
       " 'machine_learning',\n",
       " 'good_night',\n",
       " 'learning_algorithms',\n",
       " 'front_end',\n",
       " 'ğ‘¦ğ‘œğ‘¢_ğ‘ğ‘ğ‘ğ‘˜',\n",
       " 'ğ‘Œğ‘œğ‘¢_ğ‘“ğ‘œğ‘™ğ‘™ğ‘œğ‘¤',\n",
       " 'ğ‘šğ‘’_ğ‘“ğ‘œğ‘™ğ‘™ğ‘œğ‘¤',\n",
       " 'ğ‘“ğ‘œğ‘™ğ‘™ğ‘œğ‘¤_ğ‘¦ğ‘œğ‘¢',\n",
       " 'ğ‘ğ‘ğ‘ğ‘˜_ğ‘Œğ‘œğ‘¢',\n",
       " 'ğ‘ğ‘ğ‘ğ‘˜_ig',\n",
       " 'ğ‘ğ‘ğ‘ğ‘˜_100',\n",
       " 'neovim_ğ‘Œğ‘œğ‘¢',\n",
       " 'code_neovim',\n",
       " 'thank_you',\n",
       " 'thank_service',\n",
       " 'right_thank',\n",
       " 'thank_god',\n",
       " 'thank_talking',\n",
       " 'talking_day',\n",
       " 'thank_mba',\n",
       " 'thank_mrs',\n",
       " 'mba_illa',\n",
       " 'nice_work',\n",
       " 'nice_proposals',\n",
       " 'nice_editing',\n",
       " 'nice_color',\n",
       " 'wow_nice',\n",
       " 'tiktok_nice',\n",
       " 'wow_tiktok',\n",
       " 'nice_place',\n",
       " 'amazing_beaches',\n",
       " 'im_interested',\n",
       " 'people_interested',\n",
       " 'data_visualization',\n",
       " 'hey_thread',\n",
       " 'thread_day',\n",
       " 'interested_add',\n",
       " 'im_artist',\n",
       " 'computing_python',\n",
       " 'learning_python',\n",
       " 'first_thread',\n",
       " 'hello_world',\n",
       " 'hello_friends',\n",
       " 'hello_online',\n",
       " 'hello_everyone',\n",
       " 'friends_priyam',\n",
       " 'hello_happy',\n",
       " 'happy_saturday',\n",
       " 'follow_reply',\n",
       " 'online_follow',\n",
       " 'hello_make',\n",
       " 'happy_weekend',\n",
       " 'fantastic_weekend',\n",
       " 'safe_weekend',\n",
       " 'weekend_machinelearning',\n",
       " 'average_weekend',\n",
       " 'weekend_guys',\n",
       " 'im_welcome',\n",
       " 'planned_happy',\n",
       " 'space_hope',\n",
       " 'well_planned',\n",
       " 'follow_guys',\n",
       " 'please_follow',\n",
       " 'get_followed',\n",
       " 'follow_bck',\n",
       " 'gain_together',\n",
       " 'follow_luffy',\n",
       " 'it_girls',\n",
       " 'official_think',\n",
       " 'luffy_official',\n",
       " 'amen_thank',\n",
       " 'day_amen',\n",
       " 'another_day',\n",
       " 'love_amen',\n",
       " 'amen_pray',\n",
       " 'thank_father',\n",
       " 'father_another',\n",
       " 'god_bless',\n",
       " 'god_everything',\n",
       " 'sourceig_story',\n",
       " 'story_item',\n",
       " 'item_shareigshytq3ohfvynb3m2c1',\n",
       " 'item_shareigshidmtc4mmm1ymi2ng',\n",
       " 'item_shareigshmxm0a2v2ngn6ag1ueq',\n",
       " 'item_shareigshdddnywyynjz5ym9j',\n",
       " 'item_shareigshmtdkynf3nm1vntlidw',\n",
       " 'shareigshdddnywyynjz5ym9j_asolxyprhr2w5zng0igshctvha29wodazm2sx',\n",
       " 'asolxyprhr2w5zng0igshctvha29wodazm2sx_sourceig',\n",
       " 'item_shareigshbzfra3rnanrnmgz4',\n",
       " 'frontend_developer',\n",
       " 'developer_backend',\n",
       " 'looking_connect',\n",
       " 'connect_people',\n",
       " 'java_developer',\n",
       " 'people_fields',\n",
       " 'developer_software',\n",
       " 'developer_python',\n",
       " 'robotics_openroboticsorg',\n",
       " 'fullstackopencom_data',\n",
       " 'practitioner_awstraining',\n",
       " 'bi_powerbimicrosoftcom',\n",
       " 'cloud_security',\n",
       " 'aws_cloud',\n",
       " 'apis_python',\n",
       " 'deeplearningai_apis',\n",
       " 'realpythoncom_power',\n",
       " 'chatbots_python',\n",
       " 'true_love',\n",
       " 'love_peace',\n",
       " 'tried_true',\n",
       " 'love_gc6vftbpiigshmwizddgzmnjuztaxaa',\n",
       " 'need_completely',\n",
       " 'regulation_even',\n",
       " 'others_someone',\n",
       " 'communication_selfco',\n",
       " 'resolution_empathy',\n",
       " 'even_close',\n",
       " 'really_cool',\n",
       " 'beautiful_photo',\n",
       " 'good_afternoon',\n",
       " 'afternoon_beautiful',\n",
       " 'yeah_course',\n",
       " 'beautiful_picture',\n",
       " 'beautiful_pic',\n",
       " 'cute_photo',\n",
       " 'cool_lol',\n",
       " 'happy_birthday',\n",
       " 'birthday_beta',\n",
       " 'nothing_happy',\n",
       " 'little_girl',\n",
       " 'birthday_little',\n",
       " 'special_day',\n",
       " 'day_happy',\n",
       " 'birthday_bro',\n",
       " 'friend_im',\n",
       " 'yes_sir',\n",
       " 'yes_sexy',\n",
       " 'yes_help',\n",
       " 'help_work',\n",
       " 'yes_listen',\n",
       " 'listen_wind',\n",
       " 'today_lot',\n",
       " 'go_yes',\n",
       " 'blowing_trees',\n",
       " 'trees_today',\n",
       " 'ai_artificialintelligence',\n",
       " 'machinelearning_artificialintelligence',\n",
       " 'genre_artificialintelligence',\n",
       " 'intelligent_artificialintelligence',\n",
       " 'artificialintelligenceai_artificialintelligence',\n",
       " 'control_ai',\n",
       " 'cybersecurityawarenessmonth_cybersecurity',\n",
       " 'morocco_artificialintelligence',\n",
       " 'art_midjourney',\n",
       " 'aiartwork_bigdata',\n",
       " 'ai_machinelearning',\n",
       " 'deeplearning_python',\n",
       " 'bigdata_robotics',\n",
       " 'datascience_generativeart',\n",
       " 'python_midjourneyart',\n",
       " 'generativeart_innovation',\n",
       " 'aiartcommunity_datascience',\n",
       " 'midjourneyart_programming',\n",
       " 'type_chatgpt',\n",
       " 'mean_type',\n",
       " 'chatgpt_write',\n",
       " 'prompts_freelancers',\n",
       " 'freelancers_chatgpt',\n",
       " 'dumb_chatgpt',\n",
       " 'wings_dumb',\n",
       " 'chatgpt_gives',\n",
       " 'gives_wings',\n",
       " 'best_chatgpt',\n",
       " 'helpful_thanks',\n",
       " 'use_thanks',\n",
       " 'specific_use',\n",
       " 'ok_thought',\n",
       " 'thought_specific',\n",
       " 'thanks_ok',\n",
       " 'the_dailyai1',\n",
       " 'pic_turn',\n",
       " 'click_pic',\n",
       " 'sure_feels',\n",
       " 'learning_sure',\n",
       " 'sure_know',\n",
       " 'pretty_sure',\n",
       " 'still_learning',\n",
       " 'feels_like',\n",
       " 'sure_need',\n",
       " 'humans_sure',\n",
       " 'find_talking',\n",
       " 'talking_socks',\n",
       " 'best_luck',\n",
       " 'luck_journey',\n",
       " 'good_luck',\n",
       " 'want_switch',\n",
       " 'switch_careers',\n",
       " 'careers_wish',\n",
       " 'luck_looking',\n",
       " 'collaborate_feel',\n",
       " 'looking_collaborate',\n",
       " 'wish_best',\n",
       " 'you_re',\n",
       " 'deep_learning',\n",
       " 'dont_know',\n",
       " 'social_media',\n",
       " 'merry_christmas',\n",
       " 'every_day']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "for i in range(len(bigram)):\n",
    "    bigram[i] = re.sub(\" \",\"_\", bigram[i])\n",
    "    \n",
    "bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud_visualizer = WordCloudVisualizer()\n",
    "wordcloud_visualizer.visualize(polarizing_words, output_dir, \"Bi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pasqu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\pasqu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'aston martin pics please follow simolude render design intelligenzaartificiale aiart aiphotography aicar aiartwork aiartcommunity aicars aiartist aicommunity carspotted automotive aidesign'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "\n",
    "    # Identificazione e visualizzazione temi polarizzanti\n",
    "\n",
    "    # UnGram\n",
    "    polarizing_words = clustering.identify_polarizing_themes(\n",
    "        user_opinions, cluster_labels\n",
    "    )\n",
    "    wordcloud_visualizer = WordCloudVisualizer()\n",
    "    wordcloud_visualizer.visualize(polarizing_words, output_dir, \"Un\")\n",
    "\n",
    "    # BiGram\n",
    "    polarizing_words = clustering.identify_polarizing_themes_bigram(\n",
    "        user_opinions, cluster_labels\n",
    "    )\n",
    "    wordcloud_visualizer.visualize(polarizing_words, output_dir, \"Bi\")\n",
    "\n",
    "    # TriGram\n",
    "    polarizing_words = clustering.identify_polarizing_themes_trigram(\n",
    "        user_opinions, cluster_labels\n",
    "    )\n",
    "    wordcloud_visualizer.visualize(polarizing_words, output_dir, \"Tri\")\n",
    "\n",
    "    # Topic Modeling\n",
    "\n",
    "    topic_modeling = TopicModeling()\n",
    "    lda_model, dictionary, corpus = topic_modeling.perform_topic_modeling(\n",
    "        user_opinions, len(set(cluster_labels.values()))\n",
    "    )\n",
    "\n",
    "    # Visualizzazione dei temi\n",
    "    lda_visualizer = LDAViz()\n",
    "    lda_visualizer.visualize(lda_model, corpus, dictionary, output_dir=output_dir)\n",
    "\n",
    "    logging.info(\"Processo principale completato.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
